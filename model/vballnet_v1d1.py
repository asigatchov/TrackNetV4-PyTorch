import torch
import torch.nn as nn
import numpy as np
import time


class VballNetV1d(nn.Module):
    def __init__(self, height=288, width=512, in_dim=9, out_dim=9):
        super().__init__()
        self.in_dim = in_dim
        self.out_dim = out_dim
        self.hidden_size = 1024  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 1024 –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ (64, 8, 8)

        # Stem: (B*T, 1, 288, 512) ‚Üí (B*T, 32, 144, 256)
        self.stem = nn.Sequential(
            nn.Conv2d(1, 12, kernel_size=3, padding=1),
            nn.BatchNorm2d(12),
            nn.ReLU(inplace=True),
            nn.Conv2d(12, 24, kernel_size=3, padding=1),
            nn.BatchNorm2d(24),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 288‚Üí144, 512‚Üí256
            nn.Conv2d(24, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
        )

        # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π AvgPool2d
        self.spatial_pool = nn.AvgPool2d(
            kernel_size=(18, 32), stride=(18, 32)
        )  # ‚Üí (B*T, 32, 8, 8)

        # –°–∂–∞—Ç–∏–µ
        self.feature_flatten = nn.Linear(32 * 8 * 8, self.hidden_size)  # 2048 ‚Üí 1024

        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å ONNX-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º –ø–æ–¥—Ö–æ–¥–æ–º
        self.temporal_conv1 = nn.Conv2d(
            self.hidden_size, self.hidden_size, kernel_size=3, padding=1
        )
        self.temporal_conv2 = nn.Conv2d(
            self.hidden_size, self.hidden_size, kernel_size=3, padding=1
        )
        self.temporal_act = nn.ReLU(inplace=True)

        # –î–µ–∫–æ–¥–µ—Ä —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º–∏ –∫–∞–Ω–∞–ª–∞–º–∏
        self.hidden_to_features = nn.Linear(self.hidden_size, 64 * 8 * 8)  # 1024 ‚Üí 4096
        self.feature_unflatten = nn.Unflatten(1, (64, 8, 8))

        self.upsample = nn.Sequential(
            nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1),  # 8 ‚Üí 16
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1),  # 16 ‚Üí 32
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1),  # 32 ‚Üí 64
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),  # 64 ‚Üí 128
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Upsample(size=(288, 512), mode="nearest"),
        )

        # Skip-connection
        self.skip_conv = nn.Conv2d(
            24, 32, kernel_size=1
        )  # –û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è 32 –∫–∞–Ω–∞–ª–∞–º

        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–π
        self.final_conv = nn.Conv2d(32, 1, kernel_size=1)

    def forward(self, x):
        B, T, H, W = x.shape

        if H != 288 or W != 512:
            raise ValueError(f"Input size must be (288, 512), got ({H}, {W})")

        x = x.view(B * T, 1, H, W)  # (B*T, 1, 288, 512)

        # Skip connection: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ –ø—É–ª–∏–Ω–≥–∞ (24 –∫–∞–Ω–∞–ª–æ–≤, 288x512)
        x_stem = self.stem[:4](x)  # (B*T, 24, 288, 512)
        x = self.stem[4:](x_stem)  # (B*T, 32, 144, 256)

        # –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–∂–∞—Ç–∏–µ
        x = self.spatial_pool(x)  # ‚Üí (B*T, 32, 8, 8)
        x = x.view(B * T, -1)  # flatten: (B*T, 2048)
        x = self.feature_flatten(x)  # (B*T, 1024)
        x = x.view(B, T, -1)  # (B, T, 1024)

        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
        batch_size = x.size(0)
        h_t = torch.zeros(batch_size, self.hidden_size, 1, 1).to(x.device)
        lstm_out = []

        for t in range(T):
            h_prev = h_t if t > 0 else torch.zeros_like(h_t)
            x_t = (
                x[:, t : t + 1, :]
                .transpose(1, 2)
                .view(batch_size, self.hidden_size, 1, 1)
            )
            h_t = self.temporal_conv1(h_prev + x_t)
            h_t = self.temporal_act(h_t)
            h_t = self.temporal_conv2(h_t)
            h_t = self.temporal_act(h_t)
            lstm_out.append(h_t)

        x = torch.stack(lstm_out, dim=1)  # (B, T, hidden_size, 1, 1)
        x = x.view(B * T, self.hidden_size, 1, 1)  # (B*T, hidden_size, 1, 1)

        # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
        x = x.view(B * T, -1)  # (B*T, hidden_size)
        x = self.hidden_to_features(x)  # (B*T, 64*8*8)
        x = self.feature_unflatten(x)  # (B*T, 64, 8, 8)
        x = self.upsample(x)  # (B*T, 32, 288, 512)

        # Skip-connection: 24 ‚Üí 32 –∫–∞–Ω–∞–ª–æ–≤
        x_skip = self.skip_conv(x_stem)  # (B*T, 32, 288, 512)
        x = x + x_skip  # residual

        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–π
        x = self.final_conv(x)  # (B*T, 1, 288, 512)
        x = x.reshape(B, T, 288, 512)

        # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è out_dim
        if self.out_dim > T:
            x = torch.cat([x, x[:, -1:].expand(B, self.out_dim - T, 288, 512)], dim=1)
        elif self.out_dim < T:
            x = x[:, : self.out_dim]

        return x


if __name__ == "__main__":
    print("üöÄ VballNetTiny_ONNX ‚Äî –º–æ–¥–µ–ª—å –¥–ª—è ONNX –∏ –≤—ã—Å–æ–∫–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –Ω–∞ CPU\n")

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    BATCH_SIZE = 1
    IN_DIM = 9
    OUT_DIM = 9
    HEIGHT = 288
    WIDTH = 512
    ONNX_PATH = "vballnet_tiny_cpu.onnx"

    # –¢–æ–ª—å–∫–æ CPU –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å ONNX
    device = torch.device("cpu")
    print(f"üîß –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    model = VballNetV1d(height=HEIGHT, width=WIDTH, in_dim=IN_DIM, out_dim=OUT_DIM).to(
        device
    )

    # –ü–æ–¥—Å—á—ë—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    total_params = sum(p.numel() for p in model.parameters())
    print(f"üßÆ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")

    # –¢–µ—Å—Ç–æ–≤—ã–π –≤–≤–æ–¥
    x_test = torch.randn(BATCH_SIZE, IN_DIM, HEIGHT, WIDTH)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ forward
    with torch.no_grad():
        try:
            output = model(x_test)
            print(f"‚úÖ Forward –ø—Ä–æ—à—ë–ª —É—Å–ø–µ—à–Ω–æ. –í—ã—Ö–æ–¥: {output.shape}")
            assert output.shape == (
                BATCH_SIZE,
                OUT_DIM,
                HEIGHT,
                WIDTH,
            ), "–ù–µ–≤–µ—Ä–Ω–∞—è —Ñ–æ—Ä–º–∞ –≤—ã—Ö–æ–¥–∞"
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ forward: {e}")
            raise

    # üì¶ –≠–ö–°–ü–û–†–¢ –í ONNX
    print(f"\nüì¶ –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ ONNX: {ONNX_PATH}")

    model.eval()
    dynamic_axes = {"input": {0: "batch", 1: "time"}, "output": {0: "batch", 1: "time"}}

    try:
        torch.onnx.export(
            model,
            x_test,
            ONNX_PATH,
            export_params=True,
            opset_version=13,
            do_constant_folding=True,
            input_names=["input"],
            output_names=["output"],
            dynamic_axes=dynamic_axes,
            verbose=False,
        )
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ {ONNX_PATH}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ ONNX: {e}")
        raise

    # ‚è±Ô∏è –ó–ê–ú–ï–† –°–ö–û–†–û–°–¢–ò –í ONNX RUNTIME
    try:
        import onnxruntime as ort

        print("\n‚è±Ô∏è  –ó–∞–ø—É—Å–∫ ONNX Runtime (CPU) –¥–ª—è –∑–∞–º–µ—Ä–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏...")

        sess_options = ort.SessionOptions()
        sess_options.intra_op_num_threads = 4
        sess_options.graph_optimization_level = (
            ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        )

        ort_session = ort.InferenceSession(
            ONNX_PATH, sess_options=sess_options, providers=["CPUExecutionProvider"]
        )

        print(f"‚úÖ ONNX Runtime –∑–∞–ø—É—â–µ–Ω. –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {ort_session.get_providers()[0]}")

        x_np = np.random.randn(BATCH_SIZE, IN_DIM, HEIGHT, WIDTH).astype(np.float32)

        for _ in range(10):
            ort_session.run(None, {"input": x_np})

        n_runs = 100
        start = time.time()
        for _ in range(n_runs):
            ort_session.run(None, {"input": x_np})
        end = time.time()

        avg_time_ms = (end - start) / n_runs * 1000
        fps = 1000 / avg_time_ms

        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ CPU:")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_time_ms:.3f} –º—Å")
        print(f"   –°–∫–æ—Ä–æ—Å—Ç—å: {fps:.2f} FPS")
        print(f"‚úÖ {'–î–æ—Å—Ç–∏–≥–Ω—É—Ç 40+ FPS' if fps >= 40 else '–ù–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç 40 FPS'}")

    except ImportError:
        print("\n‚ö†Ô∏è  onnxruntime –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏: pip install onnxruntime")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ ONNX Runtime: {e}")

    print("\nüéâ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ production!")
