import torch
import torch.nn as nn
import numpy as np
import time
import torch
import torch.nn as nn
import numpy as np
import time

class VballNetV1d(nn.Module):
    def __init__(self, height=288, width=512, in_dim=9, out_dim=9):
        super().__init__()
        self.in_dim = in_dim
        self.out_dim = out_dim
        self.hidden_size = 128  # –£–≤–µ–ª–∏—á–µ–Ω–æ

        # Stem: (B*T, 1, 288, 512) ‚Üí (B*T, 32, 144, 256)
        self.stem = nn.Sequential(
            nn.Conv2d(1, 12, kernel_size=3, padding=1),
            nn.BatchNorm2d(12),
            nn.ReLU(inplace=True),
            nn.Conv2d(12, 24, kernel_size=3, padding=1),
            nn.BatchNorm2d(24),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 288‚Üí144, 512‚Üí256
            nn.Conv2d(24, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
        )

        # ‚úÖ –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π AvgPool2d –≤–º–µ—Å—Ç–æ AdaptiveAvgPool2d
        # –í—Ö–æ–¥ –ø–æ—Å–ª–µ stem: (144, 256)
        # –¶–µ–ª—å: (8, 8) ‚Üí kernel = (144//8, 256//8) = (18, 32)
        self.spatial_pool = nn.AvgPool2d(kernel_size=(18, 32), stride=(18, 32))  # ‚Üí (B*T, 32, 8, 8)

        # –°–∂–∞—Ç–∏–µ
        self.feature_flatten = nn.Linear(32 * 8 * 8, self.hidden_size)  # 2048 ‚Üí 128

        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        self.temporal_conv = nn.Conv1d(self.hidden_size, self.hidden_size, kernel_size=3, padding=1)
        self.temporal_act = nn.ReLU(inplace=True)

        # –î–µ–∫–æ–¥–µ—Ä
        self.hidden_to_features = nn.Linear(self.hidden_size, 32 * 8 * 8)  # 128 ‚Üí 2048
        self.feature_unflatten = nn.Unflatten(1, (32, 8, 8))

        # –ê–ø—Å–∫–µ–π–ª
        self.upsample = nn.Sequential(
            nn.ConvTranspose2d(32, 32, kernel_size=4, stride=2, padding=1),  # 8 ‚Üí 16
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(32, 32, kernel_size=4, stride=2, padding=1),  # 16 ‚Üí 32
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),  # 32 ‚Üí 64
            nn.BatchNorm2d(16),
            nn.ReLU(inplace=True),
            nn.Upsample(size=(288, 512), mode='nearest'),
        )

        # Skip-connection
        self.skip_conv = nn.Conv2d(24, 16, kernel_size=1)  # –æ–±—É—á–∞–µ–º—ã–π

        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–π
        self.final_conv = nn.Conv2d(16, 1, kernel_size=1)
    def forward(self, x):
        B, T, H, W = x.shape

        if H != 288 or W != 512:
            raise ValueError(f"Input size must be (288, 512), got ({H}, {W})")

        x = x.view(B * T, 1, H, W)  # (B*T, 1, 288, 512)

        # Skip connection: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ –ø—É–ª–∏–Ω–≥–∞ (24 –∫–∞–Ω–∞–ª–æ–≤, 288x512)
        x_stem = self.stem[:4](x)  # (B*T, 24, 288, 512)
        x = self.stem[4:](x_stem)   # (B*T, 32, 144, 256)

        # –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–∂–∞—Ç–∏–µ
        x = self.spatial_pool(x)  # ‚Üí (B*T, 32, 8, 8)
        x = x.view(B * T, -1)     # flatten: (B*T, 2048)
        x = self.feature_flatten(x)  # (B*T, 128)
        x = x.view(B, T, -1)      # (B, T, 128)

        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        x = x.transpose(1, 2)  # (B, 128, T)
        x = self.temporal_conv(x)
        x = self.temporal_act(x)
        x = x.transpose(1, 2)  # (B, T, 128)

        # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞
        x = x.reshape(B * T, -1)  # (B*T, 128)
        x = self.hidden_to_features(x)  # (B*T, 2048)
        x = self.feature_unflatten(x)  # (B*T, 32, 8, 8)
        x = self.upsample(x)  # (B*T, 16, 288, 512)

        # Skip-connection: 24 ‚Üí 16 –∫–∞–Ω–∞–ª–æ–≤ (–æ–±—É—á–∞–µ–º—ã–π —Å–ª–æ–π)
        x_skip = self.skip_conv(x_stem)  # (B*T, 16, 288, 512)
        x = x + x_skip  # residual

        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–π
        x = self.final_conv(x)  # (B*T, 1, 288, 512)
        x = x.reshape(B, T, 288, 512)

        # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è out_dim
        if self.out_dim > T:
            x = torch.cat([x, x[:, -1:].expand(B, self.out_dim - T, 288, 512)], dim=1)
        elif self.out_dim < T:
            x = x[:, :self.out_dim]

        return x
    

if __name__ == "__main__":
    print("üöÄ VballNetTiny_ONNX ‚Äî –º–æ–¥–µ–ª—å –¥–ª—è ONNX –∏ –≤—ã—Å–æ–∫–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –Ω–∞ CPU\n")

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    BATCH_SIZE = 1
    IN_DIM = 9
    OUT_DIM = 9
    HEIGHT = 288
    WIDTH = 512
    ONNX_PATH = "vballnet_tiny_cpu.onnx"

    # –¢–æ–ª—å–∫–æ CPU –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å ONNX
    device = torch.device("cpu")
    print(f"üîß –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    model = VballNetV1d(
        height=HEIGHT,
        width=WIDTH,
        in_dim=IN_DIM,
        out_dim=OUT_DIM
    ).to(device)

    # –ü–æ–¥—Å—á—ë—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    total_params = sum(p.numel() for p in model.parameters())
    print(f"üßÆ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")

    # –¢–µ—Å—Ç–æ–≤—ã–π –≤–≤–æ–¥
    x_test = torch.randn(BATCH_SIZE, IN_DIM, HEIGHT, WIDTH)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ forward
    with torch.no_grad():
        try:
            output = model(x_test)
            print(f"‚úÖ Forward –ø—Ä–æ—à—ë–ª —É—Å–ø–µ—à–Ω–æ. –í—ã—Ö–æ–¥: {output.shape}")
            assert output.shape == (BATCH_SIZE, OUT_DIM, HEIGHT, WIDTH), "–ù–µ–≤–µ—Ä–Ω–∞—è —Ñ–æ—Ä–º–∞ –≤—ã—Ö–æ–¥–∞"
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ forward: {e}")
            raise

    # ---------------------------------------------
    # üì¶ –≠–ö–°–ü–û–†–¢ –í ONNX
    # ---------------------------------------------
    print(f"\nüì¶ –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ ONNX: {ONNX_PATH}")

    model.eval()
    dynamic_axes = {
        'input': {0: 'batch', 1: 'time'},
        'output': {0: 'batch', 1: 'time'}
    }

    try:
        torch.onnx.export(
            model,
            x_test,
            ONNX_PATH,
            export_params=True,
            opset_version=13,
            do_constant_folding=True,
            input_names=['input'],
            output_names=['output'],
            dynamic_axes=dynamic_axes,
            verbose=False
        )
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ {ONNX_PATH}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ ONNX: {e}")
        raise

    # ---------------------------------------------
    # ‚è±Ô∏è –ó–ê–ú–ï–† –°–ö–û–†–û–°–¢–ò –í ONNX RUNTIME
    # ---------------------------------------------
    try:
        import onnxruntime as ort

        print("\n‚è±Ô∏è  –ó–∞–ø—É—Å–∫ ONNX Runtime (CPU) –¥–ª—è –∑–∞–º–µ—Ä–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏...")

        # –û–ø—Ü–∏–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        sess_options = ort.SessionOptions()
        sess_options.intra_op_num_threads = 4  # –Ω–∞—Å—Ç—Ä–æ–π –ø–æ–¥ —á–∏—Å–ª–æ —è–¥–µ—Ä
        sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL

        ort_session = ort.InferenceSession(ONNX_PATH, sess_options=sess_options, providers=['CPUExecutionProvider'])

        print(f"‚úÖ ONNX Runtime –∑–∞–ø—É—â–µ–Ω. –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {ort_session.get_providers()[0]}")

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        x_np = np.random.randn(BATCH_SIZE, IN_DIM, HEIGHT, WIDTH).astype(np.float32)

        # –ü—Ä–æ–≥—Ä–µ–≤
        for _ in range(10):
            ort_session.run(None, {'input': x_np})

        # –ó–∞–º–µ—Ä
        n_runs = 100
        start = time.time()
        for _ in range(n_runs):
            ort_session.run(None, {'input': x_np})
        end = time.time()

        avg_time_ms = (end - start) / n_runs * 1000
        fps = 1000 / avg_time_ms

        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ CPU:")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_time_ms:.3f} –º—Å")
        print(f"   –°–∫–æ—Ä–æ—Å—Ç—å: {fps:.2f} FPS")
        print(f"‚úÖ {'–î–æ—Å—Ç–∏–≥–Ω—É—Ç 40+ FPS' if fps >= 40 else '–ù–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç 40 FPS'}")

    except ImportError:
        print("\n‚ö†Ô∏è  onnxruntime –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏: pip install onnxruntime")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ ONNX Runtime: {e}")

    print("\nüéâ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ production!")