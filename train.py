import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset
import torch.nn.functional as F
import time
import json
import logging
import warnings
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
import matplotlib.pyplot as plt
from tqdm import tqdm
import numpy as np

from tracknet import TrackNet, WeightedBCELoss
from dataset_controller.ball_tracking_data_reader import BallTrackingDataset

# ======================== TrackNetV2 è®ºæ–‡é…ç½®å‚æ•° ========================
TRAINING_CONFIG = {
    "training": {
        "batch_size": 2,  # æ ¹æ®è®ºæ–‡ï¼Œå°æ‰¹æ¬¡ä¿è¯ç¨³å®šè®­ç»ƒ
        "num_epochs": 30,  # è®ºæ–‡ä¸­ä½¿ç”¨30ä¸ªepoch
        "learning_rate": 1.0,  # è®ºæ–‡ä¸­Adadeltaä½¿ç”¨lr=1.0
        "weight_decay": 0.0,  # è®ºæ–‡ä¸­æœªæåŠï¼Œä¿æŒä¸º0
        "gradient_clip_value": 1.0,
        "tolerance_variable": 4  # è®ºæ–‡ä¸­çš„tolerance variable
    },
    "model": {
        "input_height": 288,  # è®ºæ–‡ä¸­ä»640Ã—360é™è‡³512Ã—288
        "input_width": 512,
        "heatmap_radius": 3,  # é«˜æ–¯çƒ­å›¾åŠå¾„
        "detection_threshold": 0.5,  # è®ºæ–‡ä¸­ä½¿ç”¨0.5ä½œä¸ºé˜ˆå€¼
        "distance_threshold": 4  # è®ºæ–‡ä¸­ä½¿ç”¨4åƒç´ ä½œä¸ºè·ç¦»é˜ˆå€¼
    },
    "optimization": {
        "scheduler_factor": 0.5,
        "scheduler_patience": 8,
        "min_lr": 1e-6
    },
    "early_stopping": {
        "enabled": True,
        "patience": 15,
        "min_delta": 1e-6
    },
    "logging": {
        "save_interval": 5,
        "plot_interval": 5,
        "log_level": "INFO"
    },
    "paths": {
        "save_dir": "checkpoints",
        "log_dir": "logs"
    },
    "data": {
        "num_workers": 2,  # MPSè®¾å¤‡å»ºè®®è¾ƒå°‘workers
        "pin_memory": False,  # MPSè®¾å¤‡ä¸æ”¯æŒpin_memory
        "persistent_workers": False,  # MPSè®¾å¤‡å»ºè®®å…³é—­
        "train_split": 0.8
    }
}

# è®ºæ–‡ä¸­çš„æ•°æ®é›†é…ç½®
DATASET_CONFIGS = {
    "3in3out": {  # è®ºæ–‡ä¸­çš„MIMOè®¾è®¡
        "input_frames": 3,
        "output_frames": 3,
        "normalize_coords": True,
        "normalize_pixels": True,
        "video_ext": ".mp4",
        "csv_suffix": "_ball.csv"
    },
    "3in1out": {  # ä¼ ç»ŸMISOè®¾è®¡ä½œä¸ºå¯¹æ¯”
        "input_frames": 3,
        "output_frames": 1,
        "normalize_coords": True,
        "normalize_pixels": True,
        "video_ext": ".mp4",
        "csv_suffix": "_ball.csv"
    }
}


def setup_logging(log_dir: Path, config_name: str) -> logging.Logger:
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_dir.mkdir(exist_ok=True)

    logger = logging.getLogger(f'tracknetv2_{config_name}')
    logger.setLevel(logging.INFO)
    logger.handlers.clear()

    # æ–‡ä»¶handler
    file_handler = logging.FileHandler(log_dir / f'training_{config_name}.log')
    file_handler.setLevel(logging.INFO)

    # æ§åˆ¶å°handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)

    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger


def get_device() -> torch.device:
    """è·å–æœ€ä½³å¯ç”¨è®¾å¤‡ï¼Œå¤„ç†MPSå…¼å®¹æ€§"""
    if torch.cuda.is_available():
        device = torch.device('cuda')
        device_name = torch.cuda.get_device_name()
        memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"âœ“ ä½¿ç”¨CUDAè®¾å¤‡: {device_name} ({memory:.1f}GB)")
        return device
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        device = torch.device('mps')
        print("âœ“ ä½¿ç”¨MPSè®¾å¤‡ (Apple Silicon)")
        print("  æ³¨æ„: MPSè®¾å¤‡å°†è‡ªåŠ¨ç¦ç”¨pin_memoryå’Œpersistent_workers")
        return device
    else:
        device = torch.device('cpu')
        print("âœ“ ä½¿ç”¨CPUè®¾å¤‡")
        return device


def load_all_matches(professional_dir: Path, config: Dict) -> BallTrackingDataset:
    """åŠ è½½æ‰€æœ‰matchæ–‡ä»¶å¤¹å¹¶åˆå¹¶æ•°æ®é›†"""
    professional_dir = Path(professional_dir)
    match_dirs = sorted([
        d for d in professional_dir.iterdir()
        if d.is_dir() and d.name.startswith('match')
    ])

    if not match_dirs:
        raise ValueError(f"åœ¨ {professional_dir} ä¸­æœªæ‰¾åˆ°matchæ–‡ä»¶å¤¹")

    combined_dataset = None
    total_samples = 0

    print(f"æ­£åœ¨åŠ è½½æ•°æ®é›†...")
    for match_dir in match_dirs:
        try:
            dataset = BallTrackingDataset(str(match_dir), config=config)
            if len(dataset) > 0:
                if combined_dataset is None:
                    combined_dataset = dataset
                else:
                    combined_dataset = combined_dataset + dataset
                total_samples += len(dataset)
                print(f"  âœ“ {match_dir.name}: {len(dataset)} ä¸ªæ ·æœ¬")
        except Exception as e:
            print(f"  âœ— {match_dir.name} åŠ è½½å¤±è´¥: {e}")

    if combined_dataset is None:
        raise ValueError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®é›†")

    print(f"æ•°æ®é›†åŠ è½½å®Œæˆï¼Œæ€»è®¡: {total_samples} ä¸ªæ ·æœ¬")
    return combined_dataset


def create_gaussian_heatmap(
        x: float, y: float, visibility: float,
        height: int, width: int, radius: float = 3.0
) -> torch.Tensor:
    """æŒ‰ç…§è®ºæ–‡åˆ›å»ºé«˜æ–¯çƒ­å›¾ï¼ˆå®å€¼2Dæ•°ç»„è€Œéone-hotç¼–ç ï¼‰"""
    heatmap = torch.zeros(height, width, dtype=torch.float32)

    if visibility < 0.5:
        return heatmap

    # è®¡ç®—åƒç´ åæ ‡
    x_pixel = max(0, min(width - 1, int(x * width)))
    y_pixel = max(0, min(height - 1, int(y * height)))

    # ä¼˜åŒ–è®¡ç®—ï¼šä»…åœ¨æœ‰æ•ˆåŒºåŸŸè®¡ç®—é«˜æ–¯å€¼
    kernel_size = int(3 * radius)
    x_min = max(0, x_pixel - kernel_size)
    x_max = min(width, x_pixel + kernel_size + 1)
    y_min = max(0, y_pixel - kernel_size)
    y_max = min(height, y_pixel + kernel_size + 1)

    if x_max <= x_min or y_max <= y_min:
        return heatmap

    # åœ¨æœ‰æ•ˆåŒºåŸŸç”Ÿæˆé«˜æ–¯åˆ†å¸ƒ
    y_coords, x_coords = torch.meshgrid(
        torch.arange(y_min, y_max, dtype=torch.float32),
        torch.arange(x_min, x_max, dtype=torch.float32),
        indexing='ij'
    )

    dist_sq = (x_coords - x_pixel) ** 2 + (y_coords - y_pixel) ** 2
    gaussian_values = torch.exp(-dist_sq / (2 * radius ** 2))

    # è®ºæ–‡ä¸­æåˆ°çš„é˜ˆå€¼å¤„ç†
    gaussian_values[gaussian_values < 0.01] = 0

    heatmap[y_min:y_max, x_min:x_max] = gaussian_values

    return heatmap


def collate_fn(batch: List[Tuple]) -> Tuple[torch.Tensor, torch.Tensor]:
    """TrackNetV2æ•°æ®æ•´ç†å‡½æ•°"""
    config = TRAINING_CONFIG["model"]
    target_height = config["input_height"]
    target_width = config["input_width"]
    radius = config["heatmap_radius"]

    frames_list = []
    heatmaps_list = []

    for frames, labels in batch:
        # è°ƒæ•´è¾“å…¥å°ºå¯¸åˆ°è®ºæ–‡æŒ‡å®šçš„512Ã—288
        frames = frames.unsqueeze(0)
        frames_resized = F.interpolate(
            frames,
            size=(target_height, target_width),
            mode='bilinear',
            align_corners=False,
            antialias=True
        )
        frames_resized = frames_resized.squeeze(0)
        frames_list.append(frames_resized)

        # æŒ‰ç…§è®ºæ–‡ç”Ÿæˆå®å€¼çƒ­å›¾
        num_frames = len(labels)
        heatmaps = torch.zeros(num_frames, target_height, target_width, dtype=torch.float32)

        for i, label_dict in enumerate(labels):
            if isinstance(label_dict, dict):
                x = label_dict['x'].item()
                y = label_dict['y'].item()
                visibility = label_dict['visibility'].item()

                heatmap = create_gaussian_heatmap(
                    x, y, visibility, target_height, target_width, radius
                )
                heatmaps[i] = heatmap

        heatmaps_list.append(heatmaps)

    return torch.stack(frames_list), torch.stack(heatmaps_list)


class WeightedBCELossV2(nn.Module):
    """è®ºæ–‡ä¸­çš„åŠ æƒäºŒå€¼äº¤å‰ç†µæŸå¤±å‡½æ•°"""

    def __init__(self):
        super().__init__()

    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:
        """
        å®ç°è®ºæ–‡ä¸­çš„WBCEæŸå¤±å‡½æ•°:
        WBCE = -Î£[(1-w)Â²*y_true*log(y_pred) + wÂ²*(1-y_true)*log(1-y_pred)]
        å…¶ä¸­ w = y_true (ground truthæ ‡ç­¾)
        """
        # é˜²æ­¢log(0)
        eps = 1e-7
        y_pred = torch.clamp(y_pred, eps, 1 - eps)

        # è®ºæ–‡ä¸­çš„æƒé‡ç³»æ•° w = y_true
        w = y_true

        # è®¡ç®—åŠ æƒäº¤å‰ç†µ
        term1 = (1 - w) ** 2 * y_true * torch.log(y_pred)
        term2 = w ** 2 * (1 - y_true) * torch.log(1 - y_pred)

        loss = -(term1 + term2)

        return loss.mean()


class EarlyStopping:
    """æ—©åœæœºåˆ¶"""

    def __init__(self, patience: int = 15, min_delta: float = 1e-6):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = float('inf')

    def __call__(self, val_loss: float) -> bool:
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
            return False
        else:
            self.counter += 1
            return self.counter >= self.patience


class MetricsTracker:
    """è®­ç»ƒæŒ‡æ ‡è·Ÿè¸ªå™¨"""

    def __init__(self):
        self.reset()

    def reset(self):
        self.train_losses = []
        self.val_losses = []
        self.learning_rates = []
        self.best_val_loss = float('inf')
        self.best_epoch = 0

    def update(self, train_loss: float, val_loss: float, lr: float, epoch: int):
        self.train_losses.append(train_loss)
        self.val_losses.append(val_loss)
        self.learning_rates.append(lr)

        if val_loss < self.best_val_loss:
            self.best_val_loss = val_loss
            self.best_epoch = epoch

    def get_summary(self) -> Dict:
        return {
            'best_val_loss': self.best_val_loss,
            'best_epoch': self.best_epoch,
            'final_train_loss': self.train_losses[-1] if self.train_losses else None,
            'final_val_loss': self.val_losses[-1] if self.val_losses else None,
            'total_epochs': len(self.train_losses)
        }


class TrackNetV2Trainer:
    """TrackNetV2è®­ç»ƒå™¨ï¼ˆä¸¥æ ¼æŒ‰ç…§è®ºæ–‡å®ç°ï¼‰"""

    def __init__(self, config_name: str, config: Dict = None):
        self.config = config or TRAINING_CONFIG
        self.config_name = config_name
        self.device = get_device()

        # è®¾ç½®æ—¥å¿—
        self.logger = setup_logging(self.log_dir, config_name)

        # å¤„ç†MPSè®¾å¤‡ç‰¹æ®Šé…ç½®
        self._configure_for_device()

        # åˆ›å»ºç›®å½•
        self.save_dir = Path(self.config["paths"]["save_dir"])
        self.log_dir = Path(self.config["paths"]["log_dir"])
        self.save_dir.mkdir(exist_ok=True)
        self.log_dir.mkdir(exist_ok=True)

        # åˆå§‹åŒ–ç»„ä»¶
        self.metrics = MetricsTracker()
        self.early_stopping = EarlyStopping(
            patience=self.config['early_stopping']['patience'],
            min_delta=self.config['early_stopping']['min_delta']
        )

        # è®¾ç½®æ¨¡å‹
        self.setup_model()

        # ä¿å­˜é…ç½®
        self.save_config()

        self.logger.info("TrackNetV2è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"è®¾å¤‡: {self.device}")
        self.logger.info(f"é…ç½®: {config_name}")

    def _configure_for_device(self):
        """æ ¹æ®è®¾å¤‡ç±»å‹é…ç½®å‚æ•°"""
        if self.device.type == 'mps':
            # MPSè®¾å¤‡ä¸æ”¯æŒæŸäº›åŠŸèƒ½
            self.config['data']['pin_memory'] = False
            self.config['data']['persistent_workers'] = False
            # è­¦å‘Šç”¨æˆ·
            warnings.filterwarnings("ignore", message=".*pin_memory.*MPS.*")
            self.logger.info("MPSè®¾å¤‡æ£€æµ‹åˆ°ï¼Œå·²è‡ªåŠ¨ç¦ç”¨pin_memoryå’Œpersistent_workers")
        elif self.device.type == 'cuda':
            # CUDAè®¾å¤‡å¯ç”¨æ€§èƒ½ä¼˜åŒ–
            self.config['data']['pin_memory'] = True
            self.config['data']['persistent_workers'] = True
            self.config['data']['num_workers'] = min(4, self.config['data']['num_workers'])

    def save_config(self):
        """ä¿å­˜è®­ç»ƒé…ç½®"""
        config_path = self.log_dir / f'config_{self.config_name}.json'
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump({
                'training_config': self.config,
                'dataset_config': DATASET_CONFIGS[self.config_name],
                'paper_reference': 'TrackNetV2: Efficient Shuttlecock Tracking Network (ICPAI 2020)'
            }, f, indent=2, ensure_ascii=False)

    def setup_model(self):
        """æŒ‰ç…§è®ºæ–‡è®¾ç½®æ¨¡å‹å’Œä¼˜åŒ–å™¨"""
        dataset_config = DATASET_CONFIGS[self.config_name]

        # åˆå§‹åŒ–TrackNetæ¨¡å‹
        self.model = TrackNet()

        # æ ¹æ®è¾“å‡ºå¸§æ•°è°ƒæ•´æœ€åä¸€å±‚ï¼ˆMIMOè®¾è®¡ï¼‰
        if dataset_config['output_frames'] != 3:
            # æ›¿æ¢æœ€åçš„å·ç§¯å±‚ä»¥æ”¯æŒä¸åŒçš„è¾“å‡ºå¸§æ•°
            self.model.conv2d_18 = nn.Conv2d(64, dataset_config['output_frames'], 1)

        self.model = self.model.to(self.device)

        # æ¨¡å‹å‚æ•°ç»Ÿè®¡
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)

        self.logger.info(f"æ¨¡å‹æ€»å‚æ•°: {total_params:,}")
        self.logger.info(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

        # ä½¿ç”¨è®ºæ–‡ä¸­çš„åŠ æƒBCEæŸå¤±
        self.criterion = WeightedBCELossV2()

        # è®ºæ–‡ä¸­ä½¿ç”¨Adadeltaä¼˜åŒ–å™¨ï¼Œlr=1.0
        self.optimizer = optim.Adadelta(
            self.model.parameters(),
            lr=self.config['training']['learning_rate'],
            weight_decay=self.config['training']['weight_decay']
        )

        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=self.config['optimization']['scheduler_factor'],
            patience=self.config['optimization']['scheduler_patience'],
            min_lr=self.config['optimization']['min_lr'],
            verbose=True
        )

        self.logger.info("æ¨¡å‹è®¾ç½®å®Œæˆ")
        self.logger.info(f"ä¼˜åŒ–å™¨: Adadelta (lr={self.config['training']['learning_rate']})")
        self.logger.info(f"æŸå¤±å‡½æ•°: åŠ æƒäºŒå€¼äº¤å‰ç†µ (WBCE)")

    def train_epoch(self, epoch: int, train_loader: DataLoader) -> float:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        num_batches = len(train_loader)

        progress_bar = tqdm(
            train_loader,
            desc=f"è®­ç»ƒ Epoch {epoch + 1}/{self.config['training']['num_epochs']}",
            leave=False
        )

        for batch_idx, (inputs, targets) in enumerate(progress_bar):
            inputs = inputs.to(self.device, non_blocking=True)
            targets = targets.to(self.device, non_blocking=True)

            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            outputs = self.model(inputs)

            # ç¡®ä¿è¾“å‡ºç»è¿‡sigmoidæ¿€æ´»ï¼ˆè®ºæ–‡ä¸­å¼ºè°ƒï¼‰
            if not hasattr(self.model, 'final_activation_applied'):
                outputs = torch.sigmoid(outputs)

            loss = self.criterion(outputs, targets)

            # åå‘ä¼ æ’­
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            if self.config['training']['gradient_clip_value'] > 0:
                torch.nn.utils.clip_grad_norm_(
                    self.model.parameters(),
                    self.config['training']['gradient_clip_value']
                )

            self.optimizer.step()

            total_loss += loss.item()

            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'Loss': f'{loss.item():.6f}',
                'Avg': f'{total_loss / (batch_idx + 1):.6f}'
            })

        avg_loss = total_loss / num_batches
        return avg_loss

    def validate_epoch(self, val_loader: DataLoader) -> float:
        """éªŒè¯æ¨¡å‹"""
        self.model.eval()
        total_loss = 0.0
        num_batches = len(val_loader)

        with torch.no_grad():
            progress_bar = tqdm(val_loader, desc="éªŒè¯", leave=False)
            for inputs, targets in progress_bar:
                inputs = inputs.to(self.device, non_blocking=True)
                targets = targets.to(self.device, non_blocking=True)

                outputs = self.model(inputs)

                # ç¡®ä¿è¾“å‡ºç»è¿‡sigmoidæ¿€æ´»
                if not hasattr(self.model, 'final_activation_applied'):
                    outputs = torch.sigmoid(outputs)

                loss = self.criterion(outputs, targets)
                total_loss += loss.item()

                progress_bar.set_postfix({'Loss': f'{loss.item():.6f}'})

        avg_loss = total_loss / num_batches
        return avg_loss

    def save_checkpoint(self, epoch: int, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'metrics': self.metrics.__dict__,
            'config_name': self.config_name,
            'config': self.config,
            'paper_info': 'TrackNetV2: Efficient Shuttlecock Tracking Network'
        }

        # ä¿å­˜æœ€æ–°æ¨¡å‹
        latest_path = self.save_dir / f'latest_tracknetv2_{self.config_name}.pth'
        torch.save(checkpoint, latest_path)

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_path = self.save_dir / f'best_tracknetv2_{self.config_name}.pth'
            torch.save(checkpoint, best_path)
            self.logger.info(f"âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹! éªŒè¯æŸå¤±: {self.metrics.best_val_loss:.6f}")

    def plot_training_curves(self):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        if len(self.metrics.train_losses) < 2:
            return

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'TrackNetV2è®­ç»ƒè¿‡ç¨‹ - {self.config_name}', fontsize=16)

        epochs = range(1, len(self.metrics.train_losses) + 1)

        # æŸå¤±æ›²çº¿
        axes[0, 0].plot(epochs, self.metrics.train_losses, 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
        axes[0, 0].plot(epochs, self.metrics.val_losses, 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
        axes[0, 0].axvline(x=self.metrics.best_epoch + 1, color='g', linestyle='--', alpha=0.7, label='æœ€ä½³æ¨¡å‹')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('WBCE Loss')
        axes[0, 0].set_title('åŠ æƒäºŒå€¼äº¤å‰ç†µæŸå¤±')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        # å­¦ä¹ ç‡æ›²çº¿
        if self.metrics.learning_rates:
            axes[0, 1].plot(epochs, self.metrics.learning_rates, 'g-', linewidth=2)
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('Learning Rate')
            axes[0, 1].set_title('Adadeltaå­¦ä¹ ç‡å˜åŒ–')
            axes[0, 1].set_yscale('log')
            axes[0, 1].grid(True, alpha=0.3)

        # æœ€è¿‘epochsçš„æŸå¤±
        if len(epochs) > 20:
            recent_epochs = 20
            recent_range = epochs[-recent_epochs:]
            axes[1, 0].plot(recent_range, self.metrics.train_losses[-recent_epochs:], 'b-', label='è®­ç»ƒ', linewidth=2)
            axes[1, 0].plot(recent_range, self.metrics.val_losses[-recent_epochs:], 'r-', label='éªŒè¯', linewidth=2)
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Loss')
            axes[1, 0].set_title(f'æœ€è¿‘{recent_epochs}è½®è¿›å±•')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)

        # æ”¶æ•›åˆ†æ
        if len(self.metrics.val_losses) > 5:
            # è®¡ç®—ç§»åŠ¨å¹³å‡
            window = min(5, len(self.metrics.val_losses))
            moving_avg = np.convolve(self.metrics.val_losses, np.ones(window) / window, mode='valid')
            moving_epochs = epochs[window - 1:]
            axes[1, 1].plot(epochs, self.metrics.val_losses, 'r-', alpha=0.3, label='åŸå§‹éªŒè¯æŸå¤±')
            axes[1, 1].plot(moving_epochs, moving_avg, 'r-', linewidth=2, label=f'{window}ç‚¹ç§»åŠ¨å¹³å‡')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Validation Loss')
            axes[1, 1].set_title('æ”¶æ•›åˆ†æ')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()

        # ä¿å­˜å›¾ç‰‡
        plot_path = self.log_dir / f'training_curves_tracknetv2_{self.config_name}.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()

    def train(self, train_dataset, val_dataset):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        # æ•°æ®åŠ è½½å™¨é…ç½®
        data_config = self.config['data']

        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config['training']['batch_size'],
            shuffle=False,
            num_workers=data_config['num_workers'],
            collate_fn=collate_fn,
            pin_memory=data_config['pin_memory'],
            persistent_workers=data_config['persistent_workers'],
            drop_last=True
        )

        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config['training']['batch_size'],
            shuffle=False,
            num_workers=data_config['num_workers'],
            collate_fn=collate_fn,
            pin_memory=data_config['pin_memory'],
            persistent_workers=data_config['persistent_workers'],
            drop_last=True
        )

        # è®°å½•è®­ç»ƒä¿¡æ¯
        self.logger.info("=" * 60)
        self.logger.info("å¼€å§‹TrackNetV2è®­ç»ƒ")
        self.logger.info("=" * 60)
        self.logger.info(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
        self.logger.info(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}")
        self.logger.info(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
        self.logger.info(f"éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
        self.logger.info(f"è®¾å¤‡: {self.device}")
        self.logger.info(f"é…ç½®: {self.config_name}")
        self.logger.info(f"è¾“å…¥å°ºå¯¸: {self.config['model']['input_width']}Ã—{self.config['model']['input_height']}")
        self.logger.info(f"ç›®æ ‡epochæ•°: {self.config['training']['num_epochs']}")

        start_time = time.time()

        for epoch in range(self.config['training']['num_epochs']):
            epoch_start_time = time.time()

            # è®­ç»ƒå’ŒéªŒè¯
            train_loss = self.train_epoch(epoch, train_loader)
            val_loss = self.validate_epoch(val_loader)

            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step(val_loss)
            current_lr = self.optimizer.param_groups[0]['lr']

            # æ›´æ–°æŒ‡æ ‡
            self.metrics.update(train_loss, val_loss, current_lr, epoch)

            # è®¡ç®—epochæ—¶é—´
            epoch_time = time.time() - epoch_start_time

            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
            is_best = val_loss < self.metrics.best_val_loss

            # è®°å½•è¿›åº¦
            self.logger.info(
                f"Epoch {epoch + 1:3d}/{self.config['training']['num_epochs']}: "
                f"è®­ç»ƒ={train_loss:.6f}, éªŒè¯={val_loss:.6f}, "
                f"LR={current_lr:.2e}, æ—¶é—´={epoch_time:.1f}s"
                f"{' [BEST]' if is_best else ''}"
            )

            # ä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % self.config['logging']['save_interval'] == 0 or is_best:
                self.save_checkpoint(epoch, is_best)

            # ç»˜åˆ¶æ›²çº¿
            if (epoch + 1) % self.config['logging']['plot_interval'] == 0:
                self.plot_training_curves()

            # æ—©åœæ£€æŸ¥
            if self.config['early_stopping']['enabled']:
                if self.early_stopping(val_loss):
                    self.logger.info(f"æ—©åœè§¦å‘! åœ¨ç¬¬ {epoch + 1} è½®åœæ­¢è®­ç»ƒ")
                    break

        # è®­ç»ƒå®Œæˆ
        total_time = time.time() - start_time
        summary = self.metrics.get_summary()

        self.logger.info("=" * 60)
        self.logger.info("TrackNetV2è®­ç»ƒå®Œæˆ!")
        self.logger.info("=" * 60)
        self.logger.info(f"æ€»ç”¨æ—¶: {total_time / 3600:.2f} å°æ—¶")
        self.logger.info(f"æœ€ä½³éªŒè¯æŸå¤±: {summary['best_val_loss']:.6f} (Epoch {summary['best_epoch'] + 1})")
        self.logger.info(f"æœ€ç»ˆè®­ç»ƒæŸå¤±: {summary['final_train_loss']:.6f}")
        self.logger.info(f"æœ€ç»ˆéªŒè¯æŸå¤±: {summary['final_val_loss']:.6f}")

        # è®ºæ–‡æ€§èƒ½å¯¹æ¯”ä¿¡æ¯
        self.logger.info("\nè®ºæ–‡TrackNetV2æ€§èƒ½æŒ‡æ ‡:")
        self.logger.info("- è®­ç»ƒé›†: å‡†ç¡®ç‡96.3%, ç²¾ç¡®åº¦97.0%, å¬å›ç‡98.7%")
        self.logger.info("- æµ‹è¯•é›†: å‡†ç¡®ç‡85.2%, ç²¾ç¡®åº¦97.2%, å¬å›ç‡85.4%")
        self.logger.info("- å¤„ç†é€Ÿåº¦: 31.84 FPS (3-in-3-out)")
        self.logger.info("=" * 60)

        # æœ€ç»ˆä¿å­˜
        self.save_checkpoint(epoch, False)
        self.plot_training_curves()

        return summary


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("TrackNetV2: Efficient Shuttlecock Tracking Network")
    print("åŸºäºè®ºæ–‡: TrackNetV2 (ICPAI 2020)")
    print("=" * 70)

    # è·å–æ•°æ®é›†è·¯å¾„
    base_dir = Path(__file__).resolve().parent
    professional_dir = base_dir / 'Dataset' / 'Professional'

    if not professional_dir.exists():
        print(f"âŒ é”™è¯¯: æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {professional_dir}")
        return

    # é€‰æ‹©é…ç½®
    print("\nå¯ç”¨é…ç½® (åŸºäºè®ºæ–‡è®¾è®¡):")
    print("1. 3in3out: MIMOè®¾è®¡ - 3è¾“å…¥å¸§ -> 3è¾“å‡ºå¸§ (è®ºæ–‡æ¨èï¼Œæ€§èƒ½æœ€ä½³)")
    print("2. 3in1out: MISOè®¾è®¡ - 3è¾“å…¥å¸§ -> 1è¾“å‡ºå¸§ (ä¼ ç»Ÿè®¾è®¡å¯¹æ¯”)")

    while True:
        try:
            choice = input(f"\nè¯·é€‰æ‹©é…ç½® (1-2): ").strip()
            if choice == "1":
                config_name = "3in3out"
                break
            elif choice == "2":
                config_name = "3in1out"
                break
            else:
                print("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥1æˆ–2")
        except KeyboardInterrupt:
            print("\nè®­ç»ƒå–æ¶ˆ")
            return

    print(f"\nâœ“ å·²é€‰æ‹©é…ç½®: {config_name}")
    if config_name == "3in3out":
        print("  ğŸ“Š MIMOè®¾è®¡å°†æ˜¾è‘—æå‡å¤„ç†é€Ÿåº¦ï¼ˆè®ºæ–‡ä¸­ä»2.6 FPSæå‡åˆ°31.8 FPSï¼‰")

    try:
        # åŠ è½½æ•°æ®é›†
        print(f"\næ­£åœ¨åŠ è½½æ•°æ®é›†...")
        dataset_config = DATASET_CONFIGS[config_name]
        full_dataset = load_all_matches(professional_dir, dataset_config)

        # åˆ†å‰²æ•°æ®é›†
        total_size = len(full_dataset)
        train_size = int(TRAINING_CONFIG['data']['train_split'] * total_size)
        val_size = total_size - train_size

        # åˆ›å»ºéšæœºåˆ†å‰²
        indices = torch.randperm(total_size).tolist()
        train_indices = indices[:train_size]
        val_indices = indices[train_size:]

        train_dataset = Subset(full_dataset, train_indices)
        val_dataset = Subset(full_dataset, val_indices)

        print(f"\nâœ“ æ•°æ®é›†åˆ†å‰²å®Œæˆ:")
        print(f"  è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬ ({len(train_dataset) / total_size:.1%})")
        print(f"  éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬ ({len(val_dataset) / total_size:.1%})")
        print(f"  è®ºæ–‡æ•°æ®é›†: 55,563å¸§æ¥è‡ª18ä¸ªç¾½æ¯›çƒæ¯”èµ›è§†é¢‘")

        # åˆå§‹åŒ–è®­ç»ƒå™¨
        print(f"\næ­£åœ¨åˆå§‹åŒ–TrackNetV2è®­ç»ƒå™¨...")
        trainer = TrackNetV2Trainer(config_name)

        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")
        summary = trainer.train(train_dataset, val_dataset)

        print(f"\nâœ… è®­ç»ƒæˆåŠŸå®Œæˆ!")
        print(f"ğŸ“ æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {trainer.save_dir / f'best_tracknetv2_{config_name}.pth'}")
        print(f"ğŸ“Š è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨: {trainer.log_dir}")

    except KeyboardInterrupt:
        print(f"\nâ¹ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
