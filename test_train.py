#!/usr/bin/env python3
"""
TrackNet åæ ‡æ˜ å°„å’Œçƒ­å›¾ç”Ÿæˆæµ‹è¯•å·¥å…·
ç›´æ¥è°ƒç”¨train.pyæ–‡ä»¶ä¸­çš„å‡½æ•°ï¼Œé¿å…é‡å¤å®šä¹‰
"""

import sys
from pathlib import Path

import cv2
import numpy as np

# å¯¼å…¥train.pyä¸­çš„å‡½æ•°
try:
    from train import (
        calculate_equal_ratio_resize,
        create_gaussian_heatmap,
        collate_fn,
        CONFIG,
        DATASET_CONFIG
    )

    print("âœ“ æˆåŠŸå¯¼å…¥train.pyä¸­çš„å‡½æ•°")
except ImportError as e:
    print(f"âŒ æ— æ³•å¯¼å…¥train.py: {e}")
    print("è¯·ç¡®ä¿train.pyæ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹")
    sys.exit(1)

# ===== é…ç½®åŒºåŸŸ =====
USER_CONFIG = {
    "data_dir": "Dataset/Professional",  # æ•°æ®é›†ç›®å½•è·¯å¾„
    "auto_play": True,  # æ˜¯å¦è‡ªåŠ¨æ’­æ”¾
    "playback_speed": 10,  # æ’­æ”¾é€Ÿåº¦(ms)
    "start_sample": 0,  # èµ·å§‹æ ·æœ¬ç´¢å¼•
    "match_index": 0  # ä½¿ç”¨ç¬¬å‡ ä¸ªmatchç›®å½• (0è¡¨ç¤ºç¬¬ä¸€ä¸ª)
}


def process_single_sample_like_train(frames, labels):
    """
    ä½¿ç”¨train.pyä¸­çš„collate_fné€»è¾‘å¤„ç†å•ä¸ªæ ·æœ¬
    æ¨¡æ‹Ÿbatchå¤„ç†ä½†åªå¤„ç†ä¸€ä¸ªæ ·æœ¬
    """
    # åˆ›å»ºå•æ ·æœ¬batch
    batch = [(frames, labels)]

    # ä½¿ç”¨train.pyçš„collate_fnå¤„ç†
    processed_frames, processed_heatmaps = collate_fn(batch)

    # æå–ç¬¬ä¸€ä¸ª(ä¹Ÿæ˜¯å”¯ä¸€ä¸€ä¸ª)æ ·æœ¬çš„ç»“æœ
    sample_frames = processed_frames[0]  # shape: (3, H, W)
    sample_heatmaps = processed_heatmaps[0]  # shape: (3, H, W)

    # è®¡ç®—ç”¨äºå¯è§†åŒ–çš„é¢å¤–ä¿¡æ¯
    original_height, original_width = frames.shape[-2], frames.shape[-1]
    new_height, new_width, scale_ratio = calculate_equal_ratio_resize(
        original_height, original_width,
        CONFIG["input_height"], CONFIG["input_width"]
    )

    # è®¡ç®—padding
    if new_height != CONFIG["input_height"] or new_width != CONFIG["input_width"]:
        pad_h = CONFIG["input_height"] - new_height
        pad_w = CONFIG["input_width"] - new_width
        pad_top = pad_h // 2
        pad_left = pad_w // 2
    else:
        pad_left = pad_top = 0

    # å¤„ç†åæ ‡ä¿¡æ¯ç”¨äºå¯è§†åŒ–
    processed_coords = []
    for i, label_dict in enumerate(labels):
        if isinstance(label_dict, dict):
            x_orig = label_dict['x'].item()
            y_orig = label_dict['y'].item()
            visibility = label_dict['visibility'].item()

            if visibility >= 0.5:
                # è®¡ç®—ç¼©æ”¾ååæ ‡
                x_scaled = x_orig * scale_ratio + pad_left
                y_scaled = y_orig * scale_ratio + pad_top

                # è®¡ç®—å½’ä¸€åŒ–åæ ‡
                x_norm = x_scaled / CONFIG["input_width"]
                y_norm = y_scaled / CONFIG["input_height"]

                processed_coords.append({
                    'x_orig': x_orig,
                    'y_orig': y_orig,
                    'x_scaled': x_scaled,
                    'y_scaled': y_scaled,
                    'x_norm': x_norm,
                    'y_norm': y_norm,
                    'visibility': visibility
                })
            else:
                processed_coords.append({
                    'x_orig': x_orig,
                    'y_orig': y_orig,
                    'x_scaled': -1,
                    'y_scaled': -1,
                    'x_norm': -1,
                    'y_norm': -1,
                    'visibility': visibility
                })

    return {
        'original_size': (original_height, original_width),
        'new_size': (new_height, new_width),
        'scale_ratio': scale_ratio,
        'pad_left': pad_left,
        'pad_top': pad_top,
        'frames_normalized': sample_frames,
        'heatmaps': sample_heatmaps,
        'coords': processed_coords
    }


class TrackNetVisualizer:
    def __init__(self):
        self.data_dir = Path(USER_CONFIG["data_dir"])
        self.current_sample = USER_CONFIG["start_sample"]
        self.playing = USER_CONFIG["auto_play"]
        self.delay = USER_CONFIG["playback_speed"]  # ms

        # åŠ è½½æ•°æ®é›†
        try:
            print(f"ğŸ” æ­£åœ¨åŠ è½½æ•°æ®é›†...")
            sys.path.append('.')  # æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
            from dataset_controller.ball_tracking_data_reader import BallTrackingDataset
            print(f"âœ“ æˆåŠŸå¯¼å…¥BallTrackingDataset")

            # æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
            if not self.data_dir.exists():
                raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.data_dir}")
            print(f"âœ“ æ•°æ®ç›®å½•å­˜åœ¨: {self.data_dir}")

            # æ‰¾åˆ°matchç›®å½•
            match_dirs = sorted([d for d in self.data_dir.iterdir()
                                 if d.is_dir() and d.name.startswith('match')])

            if not match_dirs:
                raise ValueError(f"åœ¨ç›®å½•ä¸­æœªæ‰¾åˆ°matchç›®å½•: {self.data_dir}")

            print(f"âœ“ æ‰¾åˆ° {len(match_dirs)} ä¸ªmatchç›®å½•: {[d.name for d in match_dirs]}")

            # ä½¿ç”¨é…ç½®æŒ‡å®šçš„matchç›®å½•
            match_index = USER_CONFIG["match_index"]
            if match_index >= len(match_dirs):
                print(f"âš ï¸ match_index {match_index} è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨ç¬¬0ä¸ª")
                match_index = 0

            selected_match = match_dirs[match_index]
            print(f"ğŸ¯ æ­£åœ¨åŠ è½½: {selected_match}")

            self.dataset = BallTrackingDataset(str(selected_match), config=DATASET_CONFIG)

            if len(self.dataset) == 0:
                raise ValueError(f"æ•°æ®é›†ä¸ºç©º: {selected_match}")

            print(f"âœ“ æ•°æ®é›†é…ç½®:")
            print(f"  - æ•°æ®ç›®å½•: {self.data_dir}")
            print(f"  - åŠ è½½match: {selected_match.name} ({match_index + 1}/{len(match_dirs)})")
            print(f"  - æ ·æœ¬æ€»æ•°: {len(self.dataset)}")
            print(f"  - èµ·å§‹æ ·æœ¬: {self.current_sample}")
            print(f"  - è‡ªåŠ¨æ’­æ”¾: {self.playing}")
            print(f"  - æ’­æ”¾é€Ÿåº¦: {self.delay}ms")

            # æ˜¾ç¤ºä½¿ç”¨çš„é…ç½®
            print(f"âœ“ ä½¿ç”¨train.pyä¸­çš„é…ç½®:")
            print(f"  - è¾“å…¥å°ºå¯¸: {CONFIG['input_height']}x{CONFIG['input_width']}")
            print(f"  - çƒ­å›¾åŠå¾„: {CONFIG['heatmap_radius']}")
            print(f"  - è¾“å…¥å¸§æ•°: {DATASET_CONFIG['input_frames']}")
            print(f"  - è¾“å‡ºå¸§æ•°: {DATASET_CONFIG['output_frames']}")

        except ImportError as e:
            print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
            print("è¯·ç¡®ä¿dataset_controller.ball_tracking_data_readeræ¨¡å—å¯ç”¨")
            print("æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®çš„å·¥ä½œç›®å½•ä¸­è¿è¡Œæ­¤è„šæœ¬")
            sys.exit(1)
        except FileNotFoundError as e:
            print(f"âŒ æ–‡ä»¶é”™è¯¯: {e}")
            print("è¯·æ£€æŸ¥USER_CONFIGä¸­çš„data_dirè·¯å¾„æ˜¯å¦æ­£ç¡®")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            traceback.print_exc()
            sys.exit(1)

    def run(self):
        """ä¸»è¿è¡Œå¾ªç¯"""
        print("\nğŸ® æ§åˆ¶è¯´æ˜:")
        print("  Space: Play/Pause")
        print("  A/D: Previous/Next sample")
        print("  Q: Quit")
        print("  +/-: Increase/Decrease playback speed")
        print("\nâœ… å¼€å§‹è¿è¡Œ...")

        while True:
            if self.current_sample >= len(self.dataset):
                self.current_sample = 0

            # è·å–å½“å‰æ ·æœ¬
            frames, labels = self.dataset[self.current_sample]

            print(f"ğŸ” Debug - Sample {self.current_sample}:")
            print(f"  - frames shape: {frames.shape}")
            print(f"  - frames dtype: {frames.dtype}")
            print(f"  - labels type: {type(labels)}")
            if isinstance(labels, (list, tuple)):
                print(f"  - labels length: {len(labels)}")
                for i, label in enumerate(labels):
                    if isinstance(label, dict):
                        print(
                            f"    - label[{i}]: x={label.get('x', 'N/A')}, y={label.get('y', 'N/A')}, vis={label.get('visibility', 'N/A')}")

            # ä½¿ç”¨train.pyçš„å¤„ç†é€»è¾‘
            result = process_single_sample_like_train(frames, labels)

            # å¯è§†åŒ–
            self.visualize_sample(result)

            # å¤„ç†æŒ‰é”®
            key = cv2.waitKey(self.delay) & 0xFF

            if key == ord('q'):
                break
            elif key == ord(' '):
                self.playing = not self.playing
            elif key == ord('a'):
                self.current_sample = max(0, self.current_sample - 1)
                self.playing = False
            elif key == ord('d'):
                self.current_sample = min(len(self.dataset) - 1, self.current_sample + 1)
                self.playing = False
            elif key == ord('+') or key == ord('='):
                self.delay = max(10, self.delay - 20)
            elif key == ord('-'):
                self.delay = min(1000, self.delay + 20)

            if self.playing:
                self.current_sample += 1

        cv2.destroyAllWindows()

    def visualize_sample(self, result):
        """å¯è§†åŒ–æ ·æœ¬"""
        frames_normalized = result['frames_normalized']
        heatmaps = result['heatmaps']
        coords = result['coords']

        # è½¬æ¢ä¸ºnumpyç”¨äºæ˜¾ç¤º
        frames_np = (frames_normalized * 255).clamp(0, 255).byte().numpy()

        print(f"ğŸ” Visualize Debug:")
        print(f"  - frames_normalized shape: {frames_normalized.shape}")
        print(f"  - frames_np shape: {frames_np.shape}")
        print(f"  - heatmaps shape: {heatmaps.shape}")

        display_images = []

        for i in range(DATASET_CONFIG["input_frames"]):  # ä½¿ç”¨é…ç½®ä¸­çš„å¸§æ•°
            # è·å–å½“å‰å¸§
            if len(frames_np.shape) == 4:  # (B, C, H, W)
                frame = frames_np[0, i]  # å–ç¬¬ä¸€ä¸ªbatchçš„ç¬¬iå¸§
            elif len(frames_np.shape) == 3:  # (C, H, W)
                frame = frames_np[i]  # ç›´æ¥å–ç¬¬iå¸§
            else:
                print(f"âŒ Unexpected frame shape: {frames_np.shape}")
                return

            print(f"  - frame[{i}] shape: {frame.shape}")

            # å¤„ç†ç°åº¦å›¾ -> RGB
            if len(frame.shape) == 2:  # ç°åº¦å›¾ (H, W)
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
            elif len(frame.shape) == 3:  # å½©è‰²å›¾ (C, H, W) -> (H, W, C)
                if frame.shape[0] == 3:  # RGB channels first
                    frame_rgb = frame.transpose(1, 2, 0)
                else:  # Already (H, W, C)
                    frame_rgb = frame
                if frame_rgb.shape[2] == 1:  # Single channel
                    frame_rgb = cv2.cvtColor(frame_rgb.squeeze(), cv2.COLOR_GRAY2BGR)
            else:
                print(f"âŒ Cannot handle frame shape: {frame.shape}")
                continue

            # åœ¨å›¾åƒä¸Šç»˜åˆ¶åæ ‡ç‚¹
            frame_with_coords = frame_rgb.copy()
            coord = coords[i] if i < len(coords) else {'visibility': 0, 'x_orig': -1, 'y_orig': -1, 'x_scaled': -1,
                                                       'y_scaled': -1, 'x_norm': -1, 'y_norm': -1}

            if coord['visibility'] >= 0.5:
                x_scaled = int(coord['x_scaled'])
                y_scaled = int(coord['y_scaled'])

                # ç»˜åˆ¶åå­—æ ‡è®°
                cv2.drawMarker(frame_with_coords, (x_scaled, y_scaled),
                               (0, 255, 0), cv2.MARKER_CROSS, 10, 2)

                # ç»˜åˆ¶åœ†åœˆ
                cv2.circle(frame_with_coords, (x_scaled, y_scaled),
                           CONFIG["heatmap_radius"], (255, 0, 0), 2)

            # æ·»åŠ åˆ†è¾¨ç‡ä¿¡æ¯
            h, w = frame_with_coords.shape[:2]
            cv2.putText(frame_with_coords, f"{w}x{h}", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

            # æ·»åŠ åæ ‡ä¿¡æ¯
            coord_text = f"Orig:({coord['x_orig']:.0f},{coord['y_orig']:.0f})"
            cv2.putText(frame_with_coords, coord_text, (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            if coord['visibility'] >= 0.5:
                scaled_text = f"Scaled:({coord['x_scaled']:.0f},{coord['y_scaled']:.0f})"
                cv2.putText(frame_with_coords, scaled_text, (10, 80),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                norm_text = f"Norm:({coord['x_norm']:.3f},{coord['y_norm']:.3f})"
                cv2.putText(frame_with_coords, norm_text, (10, 100),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            # è·å–å¯¹åº”çš„çƒ­åŠ›å›¾
            heatmap = heatmaps[i].numpy()
            heatmap_colored = cv2.applyColorMap((heatmap * 255).astype(np.uint8), cv2.COLORMAP_JET)

            # æ°´å¹³æ‹¼æ¥å›¾åƒå’Œçƒ­åŠ›å›¾
            combined = np.hstack([frame_with_coords, heatmap_colored])
            display_images.append(combined)

        # å‚ç›´æ‹¼æ¥æ‰€æœ‰å¸§
        final_display = np.vstack(display_images)

        # æ·»åŠ æ•´ä½“ä¿¡æ¯
        info_text = f"Sample: {self.current_sample}/{len(self.dataset) - 1} | "
        info_text += f"{'Playing' if self.playing else 'Paused'} | "
        info_text += f"Speed: {1000 // self.delay}fps | "
        info_text += f"Using train.py functions"

        cv2.putText(final_display, info_text, (10, final_display.shape[0] - 20),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

        # æ˜¾ç¤º
        cv2.imshow('TrackNet Test (Using train.py functions)', final_display)


def main():
    print("=" * 70)
    print("TrackNetåæ ‡æ˜ å°„å’Œçƒ­å›¾æµ‹è¯•å·¥å…· - è°ƒç”¨train.pyå‡½æ•°ç‰ˆæœ¬")
    print("=" * 70)

    # æ˜¾ç¤ºå½“å‰é…ç½®
    print("ğŸ“‹ å½“å‰USER_CONFIG:")
    for key, value in USER_CONFIG.items():
        print(f"  - {key}: {value}")

    print("\nğŸ“‹ ä½¿ç”¨train.pyä¸­çš„é…ç½®:")
    print(f"  - CONFIG: batch_size={CONFIG['batch_size']}, input_size={CONFIG['input_height']}x{CONFIG['input_width']}")
    print(
        f"  - DATASET_CONFIG: input_frames={DATASET_CONFIG['input_frames']}, output_frames={DATASET_CONFIG['output_frames']}")
    print()

    visualizer = TrackNetVisualizer()
    visualizer.run()


if __name__ == "__main__":
    main()

"""
TrackNetåæ ‡æ˜ å°„å’Œçƒ­å›¾æµ‹è¯•å·¥å…· - é‡æ„ç‰ˆæœ¬

ğŸ”„ ä¸»è¦æ”¹åŠ¨:
- ç›´æ¥å¯¼å…¥train.pyä¸­çš„å‡½æ•°: calculate_equal_ratio_resize, create_gaussian_heatmap, collate_fn
- ç§»é™¤äº†é‡å¤çš„å‡½æ•°å®šä¹‰
- ä½¿ç”¨train.pyä¸­çš„CONFIGå’ŒDATASET_CONFIG
- æ–°å¢process_single_sample_like_trainå‡½æ•°ï¼Œä½¿ç”¨train.pyçš„collate_fnå¤„ç†å•æ ·æœ¬

ğŸ“ é…ç½®è¯´æ˜:
- data_dir: æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„
- auto_play: æ˜¯å¦å¯åŠ¨æ—¶è‡ªåŠ¨æ’­æ”¾
- playback_speed: æ’­æ”¾é—´éš”(æ¯«ç§’)
- start_sample: èµ·å§‹æ ·æœ¬ç´¢å¼•
- match_index: ä½¿ç”¨å“ªä¸ªmatchç›®å½•(0=ç¬¬ä¸€ä¸ª)

ğŸ® æ§åˆ¶é”®:
- Space: æ’­æ”¾/æš‚åœ
- A/D: ä¸Šä¸€ä¸ª/ä¸‹ä¸€ä¸ªæ ·æœ¬
- Q: é€€å‡º
- +/-: å¢åŠ /å‡å°‘æ’­æ”¾é€Ÿåº¦

ğŸ“º æ˜¾ç¤ºå†…å®¹:
- æ¯å¸§æ˜¾ç¤ºï¼šåŸå›¾+åæ ‡ç‚¹ | çƒ­åŠ›å›¾
- å·¦ä¸Šè§’æ˜¾ç¤ºåˆ†è¾¨ç‡ä¿¡æ¯
- æ˜¾ç¤ºåŸå§‹åæ ‡ã€ç¼©æ”¾ååæ ‡ã€å½’ä¸€åŒ–åæ ‡
- åº•éƒ¨æ˜¾ç¤ºå½“å‰æ ·æœ¬å’Œæ’­æ”¾çŠ¶æ€
- ç°åœ¨æ˜¾ç¤º"Using train.py functions"è¡¨ç¤ºä½¿ç”¨äº†train.pyçš„å‡½æ•°

âš™ï¸ ä¿®æ”¹é…ç½®ï¼š
ç¼–è¾‘æ–‡ä»¶é¡¶éƒ¨çš„ USER_CONFIG å­—å…¸å³å¯

ğŸ”§ ä¾èµ–è¦æ±‚:
- éœ€è¦train.pyæ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹
- train.pyå¿…é¡»åŒ…å«ä»¥ä¸‹å‡½æ•°: calculate_equal_ratio_resize, create_gaussian_heatmap, collate_fn
- train.pyå¿…é¡»åŒ…å«ä»¥ä¸‹é…ç½®: CONFIG, DATASET_CONFIG
"""
